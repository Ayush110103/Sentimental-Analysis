{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.pipeline import Pipeline\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport nltk\n\n# Download NLTK stopwords\nnltk.download('punkt')\nnltk.download('stopwords')\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n\n# Basic preprocessing\n# Convert the sentiment into a binary variable: positive sentiment to 1, negative to 0\ndf['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n\ndef remove_stopwords(text):\n    stop_words = set(stopwords.words('english'))\n    word_tokens = word_tokenize(text)\n    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n    return ' '.join(filtered_text)\n\nprint(\"Removing StopWords\")\n# Apply the function to remove stopwords\ndf['review'] = df['review'].apply(lambda x: remove_stopwords(x))\n\nprint(\"Removed Splitting Dataset\")\n# Splitting the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n\n# Create a pipeline with TfidfVectorizer and RandomForestClassifier\npipeline = Pipeline([\n    ('tfidf', TfidfVectorizer(stop_words='english')),\n    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n])\n\n# Train the model\nprint(\"Training started...\")\npipeline.fit(X_train, y_train)\nprint(\"Training completed!\")\n\n# Predict on the test set\nprint(\"Predicting on the test set...\")\npredictions = pipeline.predict(X_test)\nprint(\"Prediction completed!\")\n\n# Calculate the accuracy\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:09:29.051104Z","iopub.execute_input":"2024-04-11T19:09:29.051951Z","iopub.status.idle":"2024-04-11T19:15:29.770252Z","shell.execute_reply.started":"2024-04-11T19:09:29.051905Z","shell.execute_reply":"2024-04-11T19:15:29.768971Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nRemoving StopWords\nRemoved Splitting Dataset\nTraining started...\nTraining completed!\nPredicting on the test set...\nPrediction completed!\nAccuracy: 85.92%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}